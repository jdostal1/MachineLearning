---
title: "Machine Learning Course Project"
author: "jdostal1"
date: "December 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(gbm)
library(plyr)
```

## Executive Summary
This document uses the concepts taught in the Machine Learning Class to explore the Human Activity Dataset captured by Ugulino et al. It builds a model using the training data and machine learning libraries in R, performs cross-validation on the training set to estimate the accuracy of the model without using the test set, estimates the out of sample error, explains the choices made in the process, and predicts the class of participant behavior represented by each sample in the testing data. The resultant model accurately classifies the testing data to match the correct answers for the quiz.

## Discussion
**Building the model:** The first step is a quick exploration of the data. The weight lifting dataset description at: http://groupware.les.inf.puc-rio.br/har provides some context for the classes of behavior captured in the data. After loading both data sets, the R command "summary()" is used to determine the column labels and characteristics of the features. This reveals many of the features are "NA" across all of the classes and should be omitted from the model. There are additional features (X, user_name, timestamps, etc.) that are unrelated to the behavior captured by the sensors. These features are also removed. The remaining 53 features are then used to train a Generalized Boosted Regression Model.

```{r buildModel}
# Load the training and testing datasets
training = read.csv("D:/Documents/datasciencecoursera/MachineLearning/pml-training.csv", sep = ",", header=T)
testing = read.csv("D:/Documents/datasciencecoursera/MachineLearning/pml-testing.csv", sep = ",", header=T)
# Remove features that are NA in the test set from both the training and the test sets
training1 <- training[,colSums(is.na(testing))<nrow(testing)]
testing1 <- testing[,colSums(is.na(testing))<nrow(testing)]
# Remove the features X (trial number)->num_window b/c they do not appear to  have predictive power
training2 <- training1[,c(8:length(training1[0,]))]
testing2 <- testing1[,c(8:length(testing1[0,]))]
```

**Performing Cross-Validation:** Next, k-fold cross-validation is used to estimate the accuracy of the model without using the test set. Five-fold cross-validation is used to divide the training set into five subsets. Each subset is then held out for testing while the model is trained using the remaining subsets.
``` {r crossValidation}
# Build the model using "gbm" (Generalized Boosted Regression Models) with 5-fold cross-validation
set.seed(1)
gbmControl <- trainControl(method='cv',number=5,returnResamp='none')
suppressOutput<-capture.output(modFit<-train(classe ~ ., method = "gbm", data=training2, trControl=gbmControl))
```

**Estimating Out of Sample Error:** The model is then applied to the training set to estimate the out of sample error. The class prediction generated by the model for each case is compared to the class identified in the test data and error is calculated by dividing the number of cases misclassified by the model by the total number of predictions. The out of sample error is estimated at 2.78%
```{r sampleError}
# estimate accuracy of the model applied to the training data
predictions <- predict(modFit, training2)
predictedError <- 1-(sum(predictions == training2$classe)/length(predictions))
predictedError
```

**Explaination of Choices made in the process:** There were a number of choices that are made in this process. Feature selection is determined by reviewing the description and values in the data sets. Removing features that do not have predictive power (e.g. are uniform across all observations or are uncorrelated to the behavior we are trying to predict) reduces the dimensionality of the model to improve the speed at which the model is built and improves model performance. Model selection of a Generalized Boosted Regression Model is based on the satisfactory performance of this model in course exercises. The 5-fold cross-validation is chosen based on a trade-off between accurately estimating the bias of the model and the cost of performing the validation.

**Prediction of the 20 Different Test Cases:** The predicted test cases accurately matched the quiz answers and were:
```{r prediction}
pred<-predict(modFit,testing2)
pred
```